% -*- LaTeX -*-
\documentclass{tmr}

\usepackage{mflogo}

%include polycode.fmt

\title{Error Reporting Parsers:  a Monad Transformer Approach}
\author{Matt Fenwick\email{mfenwick100@gmail.com}}

\begin{document}


\begin{introduction}
Parsing has long been one of the most fascinating and challenging applications
of programming, as evidenced by the large number of parsing libraries available
today.  However, in addition to recognizing a stream of tokens and building a parse
tree, a practical parser has many additional duties.  If parsing fails,
the location and cause of the failure must be accurately reported so that
the user can address the problem
Thus, building composable parsers which accurately report any errors
is extremely difficult.  In this article, we'll see how building
a parsing library around monad transformers allows to build clean and simple 
parsers which nevertheless provide relevant and location-specific error messages.
At the same time, we'll explore the design and some of the tradeoffs of the 
popular Haskell library for monad transformers.
\end{introduction}


\section{Parser Combinators}
Parser combinators have long been used for parsing in the 
functional programming community, represent a powerful and simple solution.
Their main advantages are ability to deal with complicated formats (see
Chomsky levels), language integration, and the declarativeness and
succinctness of the resulting parsers.
Parser combinator libraries typically include a set of basic parsers and a
set of combinators for combining little parsers into big ones.  Parsers are
typically functions whose type is something like:
\begin{verbatim}
[t] -> m (a, [t])
\end{verbatim}
where t is the token type, a is the result type, and m represents some
computational effects.
A very simple parser succeeds, consuming a single token, when the token stream
is not empty, and fails otherwise.  We can make the substitutions t -> Char,
m -> Maybe, and a -> Char and implement the function:
\begin{verbatim}
    item :: [Char] -> Maybe (Char, [Char])
    item (t:ts) = Just (t, ts)
    item []     = Nothing
    
    -- examples
    ghci$ item "abcde"
    Just ('a', "bcde")
    
    ghci$ item []
    Nothing
\end{verbatim}

We can also come up with a simple combinator that takes a parser and a function
as input, and succeeds if the parser succeeds and the function applied to the
parser's result succeeds:
\begin{verbatim}
    check :: (a -> Bool) -> ([Char] -> Maybe (a, [Char])) -> [Char] -> Maybe (a, [Char])
    check f p = p >>= \(x, ts) -> if (f x) then Just (x, ts) else Nothing
    
    -- examples
    ghci$ check (== 'a') item "abcde"
    Just ('a', "bcde")
    
    ghci$ check (== 'b') item "abcde"
    Nothing
\end{verbatim}
However, in these examples our computational effects are limited to Maybe -- we're
unable to do error reporting, logging, and so on.  Coming up with more general 
parsers and combinators will be the topic of the rest of the article.


\section{Monad transformers}
Monad transformers are a technique for combining monads to form new monads.
The motivation behind them is that while single monads are quite useful, oftentimes
the semantics of multiple monads are required simultaneously; it is then desirable
to have a modular approach for creating combined monads.

There are multiple to approaches to combining monads and to monad transformers
themselves, but we'll follow that of the standard transformers/mtl library, since
it's easy to obtain, easy to use, and quite effective in practice.

Along the way, we'll also explore some of the consequences of combining monads,
both with respect to semantics and to the definition of the Haskell language.  We'll
also bump in to some of the limitations, trade-offs and design decisions of the 
transformer/mtl library.


\section{Introducing Woof:  a Simple Lisp}
The simple language we'll use as a motivation for building parsers is 
Woof, a simple dialect of Lisp.  We'll be 
progressively adding features to a simplistic initial implementation
on our way to creating a practical, feature-rich and usable parser.

The language definition in pseudo-BNF is:

\begin{verbatim}
Woof         :=   Form(+)

Form         :=   Symbol  |  Special  |  Application

Symbol       :=  [a-zA-Z](+)

Special      :=  '{'  ( Define  |  Lambda )  '}'

Define       :=  'define'  Symbol  Form

Lambda       :=  'lambda'  '{'  Symbol(*)  '}'  Form(+)

Application  :=  '('  Form(+)  ')'

Whitespace   :=  \s+

Comment      :=  ';'  (not '\n')(*)
\end{verbatim}
With the additional rule that whitespace and comments may appear in any 
amount before any token.  Tokens are:  {, }, (, ), and Symbol.



\section{Example 1: Recognition and Tree-Building}

Parsing is "the process of analysing a 
string of symbols according to the rules of a formal grammar" (Wikipedia)
The general goal of parsing is to build a tree representing the structure
of the parsed input; further operations such as interpretation or
code generations are then performed on the tree.

The first parser we build will be responsible for determining whether input
text conforms to the language definition and simultaneously build an 
Abstract Syntax Tree representing of the structure of the recognized input.

Here's the AST definition we'll use:
\begin{verbatim}
data AST
    = ANumber Integer
    | ASymbol String
    | AString String
    | ALambda [String] [AST]
    | ADefine String AST
    | AApp    AST  [AST]
  deriving (Show, Eq)
\end{verbatim}
Plus we'll need a type for our parsers.  We'll use the basic type mentioned 
above -- \begin{verbatim}[t] -> m (a, [t]) \end{verbatim}
 -- as our starting point.  This type corresponds to our first monad transformer:  
 StateT (from Control.Monad.State), so we can write:
\begin{verbatim}
type Parser a = StateT [Char] Maybe a
\end{verbatim}
and a function for running a parser:
\begin{verbatim}
runParser :: Parser a -> String -> Maybe (a, String)
runParser = runStateT
\end{verbatim}
Which means that our Parser is a State monad transformer, with the Maybe type
as its underlying Monad parameter.

The significance of the Maybe parameter is two-fold:  it allows computational
effects to express first success versus failure, using the Just and Nothing 
constructors, respectively, and second backtracking/alternation.  We'll
capture both of these characteristics with using a type class, Plus:
\begin{verbatim}
class Applicative f => Plus f where
  zero :: f a
  (<+>) :: f a -> f a -> f a
\end{verbatim}
This type class is identical in intent to the Alternative type class from
Control.Applicative, with zero corresponding to empty and <+> to \verb+<|>+; 
however, we aren't able to use Alternative directly because
other of the monad transformers have unsuitable instances for our purposes,
and as we'll see later, inability to swap out such instances is one of the 
limitations of the monad transformer approach.  

To get around this limitation, we'll create instances for the Plus type class:
\begin{verbatim}
instance Plus Maybe where
  zero = Nothing
  Nothing <+> y = y
  x       <+> _ = x

instance (Monad m, Plus m) => Plus (StateT s m) where
  zero = StateT (const zero)
  StateT f <+> StateT g = StateT (\s -> f s <+> g s)
\end{verbatim}
Note that the StateT instance relies on its monad parameter, m, also being a 
member of the Plus type class.  This works out for our parser, since m is Maybe
and we do have a Plus instance for Maybe.

\subsection{Token parsers}
Now let's get down to the business of building parsers, starting with parsers
for our most basic syntactic elements:  tokens.
These include the four braces, symbols, strings, numbers, whitespace, and comments.
To recognize braces, we need to re-implement the item and check combinators that
we did before.  Using the MonadState and Plus type classes, 
we can now implement the basic item parser as a stateful
computation that fails if the state is empty:
\begin{verbatim}
item :: (MonadState [t] m, Plus m) => m t
item =
    get >>= \xs -> case xs of
                        (t:ts) -> put ts *> pure t;
                        []     -> zero;
\end{verbatim}
And we can easily implement a new version of the check combinator:
\begin{verbatim}
check :: (Monad m, Plus m) => (a -> Bool) -> m a -> m a
check f p =
    p >>= \x ->
    if (f x) then return x else zero
\end{verbatim}
And use both of them to build a new combinator, satisfy, that checks whether
the next character meets a condition:
\begin{verbatim}
satisfy :: (MonadState [t] m, Plus m) => (t -> Bool) -> m t
satisfy = flip check item
\end{verbatim}
And finally a parser that checks that the next character is equal to a
given character:
\begin{verbatim}
literal :: (Eq t, MonadState [t] m, Plus m) => t -> m t
literal c = satisfy ((==) c)
\end{verbatim}
Now we're ready to build parsers for the four bracket tokens.  
An exercise for the reader:  what is the inferred type of each parser?
Let's first build a parser for open curly brackets:
\begin{verbatim}
ocurly = literal '{'
\end{verbatim}
And let's try it out in ghci to make sure it does what we expect:
\begin{verbatim}
ghci$ runParser ocurly "{abc"
Just ('{', "abc")

ghci$ map (runParser  ocurly) ["}abc", "(abc", "abc"]
[Nothing, Nothing, Nothing]
\end{verbatim}
Good, it correctly accepts open curly brackets and rejects everything else.
But what about the spec that said that comments and whitespace can occur 
before any token -- will our parser be able to handle that?
\begin{verbatim}
ghci$ map (runParser  ocurly) ["}abc", "(abc", "abc"]
Nothing
\end{verbatim}
Of course not -- we haven't told it how to skip comments and whitespace yet!
Let's do that now, first by defining the whitespace and comment patterns, then
by creating a combinator (which we'll call munch) that takes in a parser, 
throws away all leading junk, then runs the parser:
\begin{verbatim}
whitespace = many1 $ satisfy (flip elem " \n\t\r\f")
comment = pure (:) <*> literal ';' <*> many0 (not1 $ literal '\n')

munch p = many0 (whitespace <+> comment) *> p
\end{verbatim}
The comment parser uses a new combinator, not1, which is built out of a new type class,
Switch, whose intention is to model computations which can be switched from successful
to failing and vice versa:
\begin{verbatim}
class Switch f where
  switch :: f a -> f ()

instance Switch Maybe where
  switch (Just _) = Nothing
  switch Nothing  = Just ()

instance (Functor m, Switch m) => Switch (StateT s m) where
  switch (StateT f) = StateT (\s -> fmap (const ((), s)) . switch $ f s)


not1 :: (MonadState [t] m, Plus m, Switch m) => m a -> m t
not1 p = switch p *> item
\end{verbatim}
And now let's fix the ocurly parser using munch and try it out:
\begin{verbatim}
ocurly = munch $ literal '{'

ghci$ map (runParser ocurly) [";abc\n  {def", "{def", "(def", "}def"]
[Just ('{',"def"),Just ('{',"def"),Nothing,Nothing]
\end{verbatim}
Excellent!  Now the open curly parser correctly throws away whitespace and comments,
and succeeds, consuming one character, when the first non-junk character is an open 
curly brace, and fails otherwise.
We can now define parsers for the other three brace tokens:
\begin{verbatim}
ccurly = munch $ literal '}'
oparen = munch $ literal '('
cparen = munch $ literal ')'
\end{verbatim}
The parser for our last token, Symbol, is slightly more complicated because it allows
multiple characters and multiple lengths.  We'll use the satisfy combinator along with 
a function that checks whether a character is one of the legal symbol characters:
\begin{verbatim}
symbol = munch $ many1 char
  where char = satisfy (flip elem (['a' .. 'z'] ++ ['A' .. 'Z']))
\end{verbatim}
Note the use of the many1 combinator to introduce repetition of any length of at least one,
and we're again using the munch combinator to throw away leading junk.

\subsection{Syntactic structures}
Whereas our token parsers dealt with the syntactic primitives of the Woof grammar, 
the remaining parsers will have to implement grammar rules that combine the tokens
into syntactic structures.
The first combining form is a function application.  The rule says that it's delimited
by matching parentheses, in between which must appear one form as the operator, followed
by any number of forms as the arguments to which the operator is applied.  We can
say that like so:
\begin{verbatim}
application =
    oparen      >>
    form        >>= \op ->
    many0 form  >>= \args ->
    cparen      >>
    return (AApp op args)
\end{verbatim}
Although this implementation uses the monadic operators >> and >>=, it could
equivalently have been implemented using the applicative combinators *> and <*>:
\begin{verbatim}
application' =
    oparen        *>
    pure AApp    <*>
    form         <*>
    many0 form   <*
    cparen
\end{verbatim}
Next, we move on to define, which is also a straightforward translation from the grammar:
\begin{verbatim}
define =
    ocurly                       *>
    check (== "define") symbol   *>
    pure ADefine                <*>
    symbol                      <*>
    form                        <*
    ccurly
\end{verbatim}
Lambda is more complicated -- not only does it have additional syntax with its parameter list,
but we also need to ensure that the parameter names are unique.  We can do that using the 
check combinator again:
\begin{verbatim}
lambda =
    ocurly                          >>
    check (== "lambda") symbol      >>
    ocurly                          >>
    check distinct (many0 symbol)   >>= \params ->
    ccurly                          >>
    many1 form                      >>= \bodies ->
    ccurly                          >>
    return (ALambda params bodies)
  where
    distinct names = length names == length (nub names)
\end{verbatim}
If the symbols are distinct, the parameter list subparser will succeed, and parsing will
continue; if there's a repeated symbol, the parsing will stop with a failure.

\subsection{Finishing touches}
Now all we have left to do is to define the special, form (which we've already used to build
the previous parsers), and woof parsers.  The special parser is simple:  it parses either 
define or lambda:
\begin{verbatim}
special = define <+> lambda
\end{verbatim}
The form parser parsers either a symbol, application, or a special form.  We could just write:
\begin{verbatim}
form = symbol <+> application <+> special
\end{verbatim}
except that the types don't match -- symbol's type parameter is a String, whereas the other two
have ASTs, so we can just fix that by mapping the correct function over symbol:
\begin{verbatim}
form = fmap ASymbol symbol <+> application <+> special
\end{verbatim}
The final parser, woof, needs to not only parse all the forms, but also make sure that the
entire input is consumed.  The end of input check is done with the end parser:
\begin{verbatim}
end = switch item
\end{verbatim}
And we also need to munch any trailing comments and whitespace, so our final woof parser is:
\begin{verbatim}
woof = many1 form <* munch end
\end{verbatim}

\subsection{Examples}
Let's look at a few examples of our parser in action:




\section{Example 2: error-reporting}
While our first attempt at a parser was useful, when it encountered malformed input, it wasn't
helpful -- all it could do was throw up its hands in despair and give up.  However, we'd like
an error message that tells us what the problem was and where it was encountered whenever bad
input is encountered.  Otherwise, we'd waste time finding the problem by eye -- not a lot of 
fun.  Here are the examples of bad input that we'd like to get specific error messages for:
\begin{itemize}
\item application: missing operator:  \begin{verbatim}()\end{verbatim}
\item application: missing close parenthesis:  \begin{verbatim}(a b\end{verbatim}
\item define: missing symbol:  \begin{verbatim}{define (a b c)}\end{verbatim}
\item define: missing form:  \begin{verbatim}{define a}\end{verbatim}
\item define: missing close curly:  \begin{verbatim}{define a b\end{verbatim}
\item lambda: missing parameter list:  \begin{verbatim}{lambda (a b c)}\end{verbatim}
\item lambda: duplicate parameter names:  \begin{verbatim}{lambda {a b a} (c d)}\end{verbatim}
\item lambda: missing parameter list close curly:  \begin{verbatim}{lambda {a b (c d)}\end{verbatim}
\item lambda: missing body form:  \begin{verbatim}{lambda {a b}}\end{verbatim}
\item lambda: missing close curly:  \begin{verbatim}{lambda {a b} (c d)\end{verbatim}
\item special form: unable to parse:  \begin{verbatim}{defin x y}\end{verbatim}
\item woof: unparsed input:  \begin{verbatim}a,b\end{verbatim}
\end{itemize}
To do this, we're going to bring in a second monad transformer type class -- MonadError -- and
another monad transformer datatype -- MaybeT.  Our parser stack and runParser function are now
going to be:
\begin{verbatim}
type Parse e t a = StateT [t] (MaybeT (Either' e)) a

runParser :: Parse e t a -> [t] -> Either' e (Maybe (a, [t]))
runParser p xs = runMaybeT (runStateT p xs)
\end{verbatim}
No, that ' isn't accidental -- we again introduce a replacement data type to avoid a type class
instance that doesn't fulfill our needs.  In this case, Either' is intended as a replacement for
Either, with the only difference being its instance of MonadError.  All other instances for 
Either' are analagous to those of Either:
\begin{verbatim}
data Either' a b
    = Left' a
    | Right' b
  deriving (Show, Eq)

instance MonadError e (Either' e) where
  throwError                =  Left'
  catchError  (Right' x) _  =  Right' x
  catchError  (Left' e)  f  =  f e
\end{verbatim}
We'll also need an instance of Switch for MaybeT:
\begin{verbatim}
instance Functor m => Switch (MaybeT m) where
  switch (MaybeT m) = MaybeT (fmap switch m)
\end{verbatim}

\subsection{Reporting position}
To be able to report the position of the error, we'll pre-process the input string, calculating
the line and column number of each character.  Then instead of our parsers operating on a list
of characters, they'll operate on a list of Tokens, where a Token is a character tupled up with
a line number and column number, which we'll express with a simple typedef and some accessor functions:
\begin{verbatim}
type Token = (Char, Int, Int)
chr  (a, _, _)  =  a
line (_, b, _)  =  b
col  (_, _, c)  =  c
\end{verbatim}
The function responsible for calculating the position will simply transform a list of characters into
a list of tokens:
\begin{verbatim}
countLineCol :: [Char] -> [Token]
countLineCol = reverse . snd . foldl f ((1, 1), [])
  where
    f ((line, col), ts) '\n' = ((line + 1, 1), ('\n', line, col):ts)
    f ((line, col), ts)  c   = ((line, col + 1), (c, line, col):ts)
\end{verbatim}

\subsection{Token parsers}
Unfortunately, by adding the position to the input, we've created a new problem for ourselves: our 
original token parsers assumed they would be operating on character lists, so we'll have to rewrite
them to get rid of that assumption.  The cause of the problem is the \verb+literal+ combinator, which
we can easily replace with this one that assumes token lists:
\begin{verbatim}
character :: (MonadState [Token] m, Plus m) => Char -> m Token
character c = satisfy ((==) c . chr)
\end{verbatim}
And now our token parsers are:
\begin{verbatim}
whitespace = many1 $ satisfy (flip elem " \n\t\r\f" . chr)
comment = pure (:) <*> character ';' <*> many0 (not1 $ character '\n')

munch p = many0 (whitespace <+> comment) *> p

ocurly = munch $ character '{'
ccurly = munch $ character '}'
oparen = munch $ character '('
cparen = munch $ character ')'
symbol = munch $ many1 char
  where char = fmap chr $ satisfy (flip elem (['a' .. 'z'] ++ ['A' .. 'Z']) . chr)
\end{verbatim}
The only differences are that literal was replaced everywhere by character, and a couple uses
of the chr accessor.  The munch combinator didn't have to change at all (although its inferred
type did in fact change).

\subsection{Error messages}
Now we get to the meat of this section -- modifying the parsers to report accurate and useful errors.
Let's start out with a list, in code, of all the errors that we're going to deal with:
\begin{verbatim}
eaOp   =  "application: missing operator"
eaCls  =  "application: missing close parenthesis"
edSym  =  "define: missing symbol"
edForm =  "define: missing form"
edCls  =  "define: missing close curly"
elPL   =  "lambda: missing parameter list"
elPrms =  "lambda: duplicate parameter names"
elPCls =  "lambda: missing parameter list close curly"
elBody =  "lambda: missing body form"
elCls  =  "lambda: missing close curly"
esName =  "special form: unable to parse"
ewUnp  =  "woof: unparsed input"
\end{verbatim}
The MonadError type class provides two useful combinators, throwError for generating errors, and 
catchError for dealing with them.  We can ignore catchError because we don't want to try to recover
from errors, we just want them reported.  Now the question is, when should an error be created
and what data should it include?  \verb+throwError+ is too basic for our needs, so we'll introduce
the \verb+commit+ combinator:
\begin{verbatim}
commit :: (MonadError e m, Plus m) => e -> m a -> m a
commit err p = p <+> throwError err
\end{verbatim}
This combinator takes two arguments: 1. an error value, and 2. a monadic computation.  It first tries
to run the computation, and if the computation fails, generates an error whose contents are the first
argument.  The definition of 'failure' is provided by the \verb+Plus+ instance of \verb+m+.
So what data do we want to include in our errors?  A String describing the error and a token reporting
the position should describe the error decently:
\begin{verbatim}
type Error = (String, Token)
\end{verbatim}
Now lets start with \verb+Application+ as our first modified, error-reporting parser:
\begin{verbatim}
application =
    oparen                       >>= \open ->
    commit (eaOp, open) form     >>= \op ->
    many0 form                   >>= \args ->
    commit (eaCls, open) cparen  >>
    return (AApp op args)
\end{verbatim}
This parser works by running the open-parenthesis parser, capturing its value in \verb+open+, and continuing
with the parsing; if either \verb+form+ or close-parenthesis fails, an appropriate error can be generated
which includes a string and the location of the open parenthesis.  However, if the open parenthesis is not
successfully parsed, it's a failure but not an error.  Here are some examples to demonstrate this in action:
\begin{verbatim}
ghci$ runParser application (countLineCol "oops")
Right' Nothing

ghci$ runParser application (countLineCol "(a b c)")
Right' (Just (AApp (ASymbol "a") [ASymbol "b",ASymbol "c"],[]))

ghci$ runParser application (countLineCol "\n()")
Left' ("application: missing operator",('(',2,1))

ghci$ runParser application (countLineCol "(a b")
Left' ("application: missing close parenthesis",('(',1,1))
\end{verbatim}
Although the previous version of the \verb+application+ parser could be implemented with just applicative combinators, 
this version certainly can't:  \verb+open+ is used to build the following parsers, making this decidedly monadic.  

The \verb+define+ and \verb+lambda+ parsers are upgraded similarly:
\begin{verbatim}
define =
    ocurly                       >>= \open ->
    check (== "define") symbol    *>
    pure ADefine                 <*>
    commit (edSym, open) symbol  <*>
    commit (edForm, open) form   <*
    commit (edCls, open) ccurly  
    
lambda =
    ocurly                               >>= \open ->
    check (== "lambda") symbol           >>
    commit (elPL, open) ocurly           >>= \p_open ->
    many0 symbol                         >>= \params ->
    (if distinct params 
        then return ()
        else throwError (elPrms, open))  >>
    commit (elPCls, open) ccurly         >>
    commit (elBody, open) (many1 form)   >>= \bodies ->
    commit (elCls, open) ccurly          >>
    return (ALambda params bodies)
  where
    distinct names = length names == length (nub names)
\end{verbatim}
Note that \verb+commit+ isn't used until we can be sure that we're in the right rule:  if, in the \verb+define+
parser, we committed to parsing the "define" keyword, we wouldn't be able to backtrack and try the \verb+lambda+
parser if that failed.  Thus, if treating errors as unrecoverable, it's important not to place a \verb+commit+
where backtracking might be necessary to parse a valid alternative.  However, this isn't the case with how
we've used it, since once we see an open curly brace and a define, we're sure that we're in the \verb+define+
rule, and allowing backtracking would only destroy our ability to produce clean and accurate error reports.

\subsection{Error messages:  finishing touches}
To complete the error-reporting parser, we need to change a couple more details.  First, we want an error 
reported when an open curly brace is found, but no special form can be reported.  To accomplish this, we
can extend the \verb+special+ parser with a third alternative, which results in an error if it can parse
an open curly brace, but in a backtracking failure if not:
\begin{verbatim}
special = define <+> lambda <+> (ocurly >>= \o -> throwError (esName, o))
\end{verbatim}
The \verb+form+ parser doesn't have to be changed:
\begin{verbatim}
form = fmap ASymbol symbol <+> application <+> special
\end{verbatim}
When we can no longer parse any forms, instead of failing, we'd like to report an error if there's any input
left, and otherwise succeed.  To implement this parser, we'll first munch any leading whitespace or comments, 
as usual, and then we'll check the input:  if it's empty, great; if not, report an error at the location of the
first remaining token, along with the appropriate error message that we defined earlier:
\begin{verbatim}
endCheck = 
    many0 (whitespace <+> comment) *>
    get >>= \xs -> case xs of
                        (t:_) -> throwError (ewUnp, t)
                        []    -> pure ()
\end{verbatim}
Now our \verb+woof+ parser uses this \verb+endCheck+ parser after it has consumed all the forms that it can:
\begin{verbatim}
woof = many0 form <* endCheck
\end{verbatim}

\subsection{Error messages:  examples}
While correct input will be parsed in the same way by our new parsers, incorrect input will now (hopefully) be
accurately reported as such.  Successful results will be slightly different, however -- there is now an extra
constructor wrapper around the value:
\begin{verbatim}
runParser woof (countLineCol "{define fgh {lambda {f x y} {define a (b c)} (f y a (a x))}}")
Right' (Just ([ADefine "fgh" 
                       (ALambda ["f","x","y"] 
                                [ADefine "a" (AApp (ASymbol "b") [ASymbol "c"]),
                                 AApp (ASymbol "f") [ASymbol "y",
                                                     ASymbol "a",
                                                     AApp (ASymbol "a") [ASymbol "x"]]])],
              []))
\end{verbatim}
Here are examples showing errors detected by the parser:
\begin{verbatim}
ghci$ map (runParser woof . countLineCol) ["()", "(a b", "{define (a b c)}",  
                                     "{define a}", "{define a b", 
                                     "{lambda (a b c)}", "{lambda {a b a} (c d)}", 
                                     "{lambda {a b (c d)}", "{lambda {a b}}", 
                                     "{lambda {a b} (c d)", "{defin x y}", "a,b"]
Left ("application: missing operator",('(',1,1))
Left ("application: missing close parenthesis",('(',1,1))
Left ("define: missing symbol",('{',1,1))
Left ("define: missing form",('{',1,1))
Left ("define: missing close curly",('{',1,1))
Left ("lambda: missing parameter list",('{',1,1))
Left ("lambda: duplicate parameter names",('{',1,1))
Left ("lambda: missing parameter list close curly",('{',1,1))
Left ("lambda: missing body form",('{',1,1))
Left ("lambda: missing close curly",('{',1,1))
Left ("special form: unable to parse",('{',1,1))
Left ("woof: unparsed input",(',',1,2))
\end{verbatim}



\section{Monad Transformer Stacks}

1. Exact vs. relative layer order; 
2. one instance per stack, even when more than one is applicable --
how to specify which one?
3. an inappropriate instance higher-up in the stack can mask a 
desired instance lower down in the stack -- that's why we had to
create a replacement for the Alternative type class and provide
some new instances for it -- to be able to use the right instances



\section{Transformer instance semantics}

Pass-through vs. deal-with, examples of each


\section{Conclusion}
Furthur applications of monad transformers to parsing:  junk logging, partial results, 
 non-deterministic parsing using the ListT or LogicT or just list data type


\bibliography{Author}

\end{document}

% -*- LaTeX -*-
\documentclass{tmr}

\usepackage{mflogo}

%include polycode.fmt

\title{Error Reporting Parsers:  a Monad Transformer Approach}
\author{Matt Fenwick\email{mfenwick100@gmail.com}}

\begin{document}


\begin{introduction}
Parsing is "the process of analysing a string of symbols according to the rules
of a formal grammar" (Wikipedia), with the general goal of building a tree
representing the structure of the parsed input, upon which further operations
such as interpretation or code generation are then performed.

In addition to recognizing a stream of tokens and building a parse tree, a
real-world parser must recognize faulty input as such, and accurately report the
location and cause of the failure.  But how -- what generates a parse error,
what information is included in the error, how do error-reporting parsers
compose?

Monad transformers provide a clean and simple answer to these questions.
We'll use them to build a parser combinator library, then we'll use the library
build a simple parser, and then we'll add in error reporting.
\end{introduction}




\section{Parser Combinators}
Parser combinators are an excellent approach for building parsers that are easy
to maintain and expressive.  In addition, they benefit from host-language
integration, allowing them to snarf features such as type systems.

Let's make a quick pass through a minimal parser combinator library so that we
can see them in action before we move on to the real stuff.  Without any 
further ado, here's the code:
\begin{verbatim}
import Control.Applicative  (Applicative(..), Alternative(..))
import Control.Monad        (liftM, ap)

newtype Parser t a = 
    Parser {getParser :: [t] -> Maybe ([t], a)}

item :: Parser t t
item = Parser f
  where 
    f [] = Nothing
    f (x:xs) = Just (xs, x)

instance Monad (Parser t) where
  return x = Parser (\ts -> Just (ts, x))
  Parser p >>= f = Parser (\ts ->
                             p ts >>= \(ts', x) ->
                             getParser (f x) ts')

instance Functor (Parser t) where
  fmap = liftM
  
instance Applicative (Parser t) where
  pure = return
  (<*>) = ap          

instance Alternative (Parser t) where
  empty = Parser (const empty)
  Parser l <|> Parser r = Parser (\ts -> l ts <|> r ts)

-- similar to mfilter, but for Alternative instead of MonadPlus
check :: (Monad f, Alternative f) => (a -> Bool) -> f a -> f a
check p m =
    m >>= \x -> if p x then return x else empty

literal :: Eq t => t -> Parser t t
literal x = afilter (== x) item
\end{verbatim}
First, we need to define the Parser type, which says that a Parser is a function
that operates on lists of tokens, producing a new list of tokens and a result
value, and possibly failing.
Next is the item parser, the simplest parser we'll deal with.  All it does is 
consume a single token if available, and succeed otherwise.
For running parsers in sequence, we'll use the combinators from the Monad and
Applicative type classes.  There's a little bit of book-keeping involved in the
Monad instance -- it has to make sure that the correct token list is used by
each parser -- but once we have a Monad instance, the Applicative and Functor
instances can be handled by imports ap and liftM from Control.Monad.
For choosing between alternatives, the MonadPlus type class will do, so we create
an instance that is defined partly in terms of the MonadPlus instance of the
underlying result type, Maybe.
Last are a couple of convenience combinators for creating specific token parsers.

Now for some examples:  first, let's see item in action.  It fails on empty lists,
and succeeds consuming one token otherwise:
\begin{verbatim}
*Main> getParser item ""
Nothing

*Main> getParser item "abcde"
Just ("bcde",'a')
\end{verbatim}
We can run parsers in sequence using the Applicative combinators.  First one parser
is run, then the second.  Note that the token position is handled such that the
second parser sees the token list output by the first parser, and that both parsers
must succeed in order for the entire parser to succeed:
\begin{verbatim}
*Main> getParser (item *> item) "abcde"
Just ("cde",'b')

*Main> getParser (fmap (,) item <*> item) "abcde"
Just ("cde",('a','b'))

*Main> getParser (item *> item) "a"
Nothing
\end{verbatim}
Parsers built out of literal only succeed when the next token matches the given
one:
\begin{verbatim}
*Main> getParser (literal 'a') "abcde"
Just ("bcde",'a')

*Main> getParser (literal 'a') "bcde"
Nothing
\end{verbatim}
Using the MonadPlus combinators, we can create parsers that succeed if any of
their sub-parsers succeed.  This is what allows parsers to backtrack, trying
various alternatives if one fails:
\begin{verbatim}
*Main> getParser (literal 'a' <|> literal 'b') "abcde"
Just ("bcde",'a')

*Main> getParser (literal 'a' <|> literal 'b') "bacde"
Just ("acde",'b')

*Main> getParser (literal 'a' <|> literal 'b') "cdeab"
Nothing
\end{verbatim}
In the rest of this article, we'll be reworking these basic parser combinators.
We'll be simplifying the implementations, extending the types of the results,
all while taking advantage of monad transformers to keep it modular.




\section{Monad transformers}
Monad transformers allow monads to be modularly combined to form new monads
which combine the semantics of their constituents.  That's exactly what we need
to do to build parsers.
We'll try to use the standard transformers/mtl libraries as much as possible, 
since they're easy to obtain, easy to use, and quite effective in practice, but
occasionally we'll have to make an extension to avoid certain type class
instances.

First, note that the parser type we used earlier -- [t] -> Maybe ([t], a) -- 
can be built out of the StateT monad transformer applied to Maybe, so the new
parser type is:
\begin{verbatim}
type Parser t a = StateT [t] Maybe a
\end{verbatim}
Now we can build the item parser using the combinators from MonadState, since
its token lists are the 'state' that it modifies.
\begin{verbatim}
{-# LANGUAGE   FlexibleContexts  #-}

import Control.Monad.State       (MonadState (..), StateT(..))

item :: (MonadState [t] m, Alternative m) => m t
item =
    get >>= \xs -> case xs of
                        (t:ts) -> put ts *> pure t;
                        []     -> empty;
\end{verbatim}
Note that we needed to use the FlexibleContexts language extension for the 
MonadState constraints in the type signatures.  This formulation of monad
transformers relies heavily on extensions to the type system, more of which 
we'll have to use for some of the later code in this article.




\section{Introducing Woof:  a Simple Lisp}
The simple language we'll use as a motivation for building parsers is 
Woof, a simple dialect of Lisp.  We'll be 
progressively adding features to a simplistic initial implementation
on our way to creating a practical, feature-rich and usable parser.

The language definition in pseudo-BNF is:

\begin{verbatim}
Woof         :=   Form(+)

Form         :=   Symbol  |  Special  |  Application

Symbol       :=  [a-zA-Z](+)

Special      :=  '{'  ( Define  |  Lambda )  '}'

Define       :=  'define'  Symbol  Form

Lambda       :=  'lambda'  '{'  Symbol(*)  '}'  Form(+)

Application  :=  '('  Form(+)  ')'

Whitespace   :=  \s+

Comment      :=  ';'  (not '\n')(*)
\end{verbatim}

With the additional rule that whitespace and comments may appear in any 
amount before any token.  Tokens are:
\begin{itemize}
\item \verb+{+
\item \verb+}+
\item \verb+(+
\item \verb+)+
\item \verb+Symbol+
\end{itemize}




\section{Example 1: Recognition and Tree-Building}

\subsection{Preliminaries}
The first Woof parser we build will be responsible for determining whether input
text conforms to the language definition and simultaneously building an 
Abstract Syntax Tree representing of the structure of the recognized input.
Here's the AST definition we'll use:
\begin{verbatim}
data AST
    = ANumber Integer
    | ASymbol String
    | AString String
    | ALambda [String] [AST]
    | ADefine String AST
    | AApp    AST  [AST]
  deriving (Show, Eq)
\end{verbatim}

We'll also want a function for running our parsers, using the type given in the
prevous section:
\begin{verbatim}
runParser :: Parser [t] a -> [t] -> Maybe (a, [t])
runParser = runStateT
\end{verbatim}

\subsection{Token parsers}
Now let's get down to the business of building parsers, starting with parsers
for our most basic syntactic elements:  tokens.
These include the four braces, symbols, strings, numbers, whitespace, and comments.
To recognize braces, we need to use the item and check combinators to build a new
 combinator, satisfy, that checks whether the next character meets a condition:
\begin{verbatim}
satisfy :: (MonadState [t] m, Alternative m) => (t -> Bool) -> m t
satisfy = flip check item
\end{verbatim}

And a combinator that checks that the next character is equal to a given character:
\begin{verbatim}
literal :: (Eq t, MonadState [t] m, Alternative m) => t -> m t
literal c = satisfy ((==) c)
\end{verbatim}

Now we're ready to build parsers for the four bracket tokens.  
First, a simple bracket parser:
\begin{verbatim}
opencurly = literal '{'
\end{verbatim}

And some examples to make sure it's behaving correctly:
\begin{verbatim}
*Main> map (runParser  opencurly) ["{abc", "}abc", "(abc", "abc"]
[Just ('{', "abc"), Nothing, Nothing, Nothing]
\end{verbatim}

Good, it correctly accepts open curly brackets and rejects everything else.
But what about the spec that said that comments and whitespace can occur 
before any token -- will our parser be able to handle that?
\begin{verbatim}
*Main> map (runParser  opencurly) ["}abc", "(abc", "abc"]
Nothing
\end{verbatim}

Of course not -- we haven't told it how to skip comments and whitespace yet!
Let's do that now, first by defining the whitespace and comment patterns, then
by creating a \verb+munch+ combinator that takes in a parser, 
throws away all leading junk, then runs the parser:
\begin{verbatim}
whitespace = many1 $ satisfy (flip elem " \n\t\r\f")
comment = pure (:) <*> literal ';' <*> many0 (not1 $ literal '\n')

munch p = many0 (whitespace <+> comment) *> p
\end{verbatim}
Here are these three parsers in action:
\begin{verbatim}
*Main> runParser whitespace "\n \t   \tabc"
Just ("\n \t   \t","abc")

*Main> runParser whitespace "abc"
Nothing

*Main> runParser comment ";123  \t\nabc"
Just (";123  \t","\nabc")

*Main> runParser (munch $ literal 'a') "abc"
Just ('a',"bc")

*Main> runParser (munch $ literal 'a') ";comment!\n   abc"
Just ('a',"bc")

*Main> runParser (munch $ literal 'a') ";comment!\n   bca"
Nothing

*Main> runParser (munch $ literal 'a') "bca"
Nothing
\end{verbatim}

The comment parser uses a new combinator, not1, which is built out of a new
type class, Switch, which models computations which can be switched from
successful to failing and vice versa:
\begin{verbatim}
class Switch f where
  switch :: f a -> f ()

instance Switch Maybe where
  switch (Just _) = Nothing
  switch Nothing  = Just ()

instance (Functor m, Switch m) => Switch (StateT s m) where
  switch (StateT f) = StateT (\s -> fmap (const ((), s)) . switch $ f s)

not1 :: (MonadState [t] m, Alternative m, Switch m) => m a -> m t
not1 p = switch p *> item
\end{verbatim}

With munch in hand, we can now fix opencurly and try it out:
\begin{verbatim}
opencurly = munch $ literal '{'

*Main> map (runParser opencurly) [";abc\n  {def", "{def", "(def", "}def"]
[Just ('{',"def"),Just ('{',"def"),Nothing,Nothing]
\end{verbatim}
Excellent!  Now the open curly parser correctly throws away whitespace and comments,
and succeeds, consuming one character, when the first non-junk character is an open 
curly brace, and fails otherwise.
It's straightforward to define parsers for the other three brace tokens:
\begin{verbatim}
closecurly = munch $ literal '}'
openparen  = munch $ literal '('
closeparen = munch $ literal ')'
\end{verbatim}

The parser for our last token, Symbol, is slightly more complicated because it allows
multiple characters and multiple lengths.  We'll use the satisfy combinator along with 
a function that checks whether a character is one of the legal symbol characters:
\begin{verbatim}
symbol = munch $ many1 char
  where char = satisfy (flip elem (['a' .. 'z'] ++ ['A' .. 'Z']))

*Main> runParser symbol "abc123"
Just ("abc","123")

*Main> runParser symbol ";sdfasdfsa\n  abc123"
Just ("abc","123")

*Main> runParser symbol ";sdfasdfsa\n  123abc"
Nothing
\end{verbatim}
Note the use of many1 to introduce repetition,
and we're again using munch to throw away leading junk.

\subsection{Syntactic structures}
Whereas our token parsers dealt with the syntactic primitives of the Woof grammar, 
the remaining parsers will have to implement grammar rules that combine the tokens
into syntactic structures.
The first combining form is a function application.  The rule says that it's delimited
by matching parentheses, in between which must appear one form as the operator, followed
by any number of forms as the arguments to which the operator is applied.  We can
say that like so:
\begin{verbatim}
application =
    openparen    *>
    pure AApp   <*>
    form        <*>
    many0 form  <*
    closeparen
\end{verbatim}
Note that, for now, we're doing all parser sequencing using the Applicative
combinators -- we don't need to use the monadic ones.  Also, we used pure to
inject a value -- the function AApp -- into the parser.  pure has no effect on
the tokens and always succeeds:
\begin{verbatim}
*Main> runParser (pure 3) ""
Just (3,"")

*Main> runParser (pure 3) "abc"
Just (3,"abc")
\end{verbatim}

Next, we move on to define, which is also a straightforward translation from the grammar:
\begin{verbatim}
define =
    opencurly                    *>
    check (== "define") symbol   *>
    pure ADefine                <*>
    symbol                      <*>
    form                        <*
    closecurly
\end{verbatim}

Lambda is more complicated -- not only does it have additional syntax with its parameter list,
but we also need to ensure that the parameter names are unique.  We can do that using the 
check combinator again:
\begin{verbatim}
lambda = 
    opencurly                       *>
    check (== "lambda") symbol      *>
    opencurly                       *>
    pure ALambda                   <*>
    check distinct (many0 symbol)  <*>
    (closecurly                     *>
     many1 form                    <*
     closecurly)
  where
    distinct names = length names == length (nub names)
\end{verbatim}
If the symbols are distinct, the parameter list subparser will succeed, and parsing will
continue; if there's a repeated symbol, the parsing will stop with a failure.

\subsection{Finishing touches}
Now all we have left to do is to define the special, form (which we've already used to build
the previous parsers), and woof parsers.  The special parser is simple:  it parses either 
define or lambda:
\begin{verbatim}
special = define <+> lambda
\end{verbatim}

A form is either a symbol, application, or a special form.  We could just write:
\begin{verbatim}
form = symbol <+> application <+> special
\end{verbatim}

except that the types don't match -- symbol's type parameter is a String, whereas the other two
have ASTs, so we fix that by mapping the ASymbol function over symbol:
\begin{verbatim}
form = fmap ASymbol symbol <+> application <+> special
\end{verbatim}

The final parser, woof, needs to not only parse all the forms, but also make sure that the
entire input is consumed.  The end of input check is done with the end parser:
\begin{verbatim}
end = switch item
\end{verbatim}

And we also need to munch any trailing comments and whitespace, so our final woof parser is:
\begin{verbatim}
woof = many1 form <* munch end
\end{verbatim}

\subsection{Examples}
Let's look at a few examples of our parser in action:
\begin{verbatim}
*Main> runParser woof "; \n   {lambda {x y z} a b (c b a)}end"
Just ([ALambda ["x","y","z"] 
               [ASymbol "a",
                ASymbol "b",
                AApp (ASymbol "c") 
                     [ASymbol "b",
                      ASymbol "a"]],
       ASymbol "end"],
      "")

*Main> runParser woof "a b c {define q (f x)}"
Just ([ASymbol "a",
       ASymbol "b",
       ASymbol "c",
       ADefine "q" (AApp (ASymbol "f") [ASymbol "x"])],"")

*Main> runParser woof "a b c {define q (f x)},"
Nothing
\end{verbatim}
Note that the first two parses consume the entire input, which the last one 
fails because it can't recognize the trailing comma.




\section{Example 2: error-reporting}
While our first parser worked great when the input was valid, it wasn't helpful
at all when the input was malformed.  We'd like it to produce an error message
that tells us what the problem was and where it was encountered whenever bad
input is encountered.  Otherwise, we'd waste time finding the problem by eye 
-- not a lot of fun.  

To solve this problem, let's start with an informal spec outlining the error
messages that we expect to get, and the malformed input that causes each of them: 
\begin{itemize}
\item application: missing operator:  \begin{verbatim}()\end{verbatim}
\item application: missing close parenthesis:  \begin{verbatim}(a b\end{verbatim}
\item define: missing symbol:  \begin{verbatim}{define (a b c)}\end{verbatim}
\item define: missing form:  \begin{verbatim}{define a}\end{verbatim}
\item define: missing close curly:  \begin{verbatim}{define a b\end{verbatim}
\item lambda: missing parameter list:  \begin{verbatim}{lambda (a b c)}\end{verbatim}
\item lambda: duplicate parameter names:  \begin{verbatim}{lambda {a b a} (c d)}\end{verbatim}
\item lambda: missing parameter list close curly:  \begin{verbatim}{lambda {a b (c d)}\end{verbatim}
\item lambda: missing body form:  \begin{verbatim}{lambda {a b}}\end{verbatim}
\item lambda: missing close curly:  \begin{verbatim}{lambda {a b} (c d)\end{verbatim}
\item special form: unable to parse:  \begin{verbatim}{defin x y}\end{verbatim}
\item woof: unparsed input:  \begin{verbatim}a,b\end{verbatim}
\end{itemize}
To do this, we're going to bring in a second monad transformer type class -- MonadError -- and
another monad transformer datatype -- MaybeT.  Our parser stack and runParser function are now:
\begin{verbatim}
type Parse e t a = StateT [t] (MaybeT (Either e)) a

runParser :: Parse e t a -> [t] -> Either e (Maybe (a, [t]))
runParser p xs = runMaybeT (runStateT p xs)
\end{verbatim}
Now we have three different possible results:  success, failure, and an error:
\begin{verbatim}
*Main> runParser item "abc"
Right (Just ('a',"bc"))

*Main> runParser item ""
Right Nothing

*Main> runParser (throwError "oops!") ""
Left "oops!"
\end{verbatim}
Although the choice combinator can recover from failures, it can't recover from
errors.  Compare:
\begin{verbatim}
*Main> runParser (satisfy (== 'a') <|> satisfy (== 'b')) "babc"
Right (Just ('b',"abc"))

*Main> runParser (throwError "no backtracking!" <|> satisfy (== 'b')) "babc"
Left "no backtracking!"
\end{verbatim}
We'll take advantage of this backtracking restriction to produce accurate error
messages.

\subsection{Type Class Preliminaries}
Unfortunately, the standard MonadError instance for the Either datatype does
not fit our needs -- it requires an Error constraint that we do not want.  To
solve this problem, we'll implement our own MonadError type class, based on the
standard one, and instances of it.  We'll need an instance for each member of
our stack -- Either, StateT, and MaybeT: 
\begin{verbatim}
class Monad m => MonadError e m | m -> e where
  throwError :: e -> m a
  catchError :: m a -> (e -> m a) -> m a

instance MonadError e (Either e) where
  throwError               =  Left
  catchError  (Right x) _  =  Right x
  catchError  (Left e)  f  =  f e
  
instance MonadError e m => MonadError e (StateT s m) where
  throwError      =  lift . throwError
  catchError m f  =  StateT (\s -> catchError (runStateT m s) 
                                              (\e -> runStateT (f e) s))

instance MonadError e m => MonadError e (MaybeT m) where
  throwError      =  lift . throwError
  catchError m f  =  MaybeT $ catchError (runMaybeT m) (runMaybeT . f)
\end{verbatim}
Note how the StateT and MaybeT instances don't really do anything with the
errors; they just pass the error on through to the next level.  That's why they
both require that the next lower level supports MonadError.  Also, this code 
requires some additional extensions:
\begin{itemize}
\item FlexibleInstances
\item FunctionalDependencies
\item UndecidableInstances 
\end{itemize}

We'll also need an instance of Switch for MaybeT:
\begin{verbatim}
instance Functor m => Switch (MaybeT m) where
  switch (MaybeT m) = MaybeT (fmap switch m)
\end{verbatim}

\subsection{Reporting position}
To be able to report the position of the error, we'll pre-process the input
string, calculating the line and column number of each character.  Then instead 
of our parsers operating on a list of characters, they'll operate on a list of 
Tokens, where a Token is a character tupled up with a line number and column 
number, which we'll express with a simple typedef and some accessor functions:
\begin{verbatim}
type Token = (Char, Int, Int)
chr  (a, _, _)  =  a
line (_, b, _)  =  b
col  (_, _, c)  =  c
\end{verbatim}
The function responsible for calculating the position will simply transform a 
list of characters into a list of tokens:
\begin{verbatim}
countLineCol :: [Char] -> [Token]
countLineCol = reverse . snd . foldl f ((1, 1), [])
  where
    f ((line, col), ts) '\n' = ((line + 1, 1), ('\n', line, col):ts)
    f ((line, col), ts)  c   = ((line, col + 1), (c, line, col):ts)
\end{verbatim}

\subsection{Token parsers}
By adding the position to the input, we've created a new problem 
for ourselves: our original token parsers operated on 
character lists, but we now need them to work on token lists.  
The cause of the problem is the \verb+literal+ combinator, so we
replace it with one for token lists:
\begin{verbatim}
character :: (MonadState [Token] m, Plus m) => Char -> m Token
character c = satisfy ((==) c . chr)
\end{verbatim}
And now our token parsers are:
\begin{verbatim}
whitespace = many1 $ satisfy (flip elem " \n\t\r\f" . chr)
comment = pure (:) <*> character ';' <*> many0 (not1 $ character '\n')

munch p = many0 (whitespace <+> comment) *> p

ocurly = munch $ character '{'
ccurly = munch $ character '}'
oparen = munch $ character '('
cparen = munch $ character ')'
symbol = munch $ many1 char
  where char = fmap chr $ satisfy (flip elem (['a' .. 'z'] ++ ['A' .. 'Z']) . chr)
\end{verbatim}
The only differences were the replacement of literal with character and a couple
uses of the chr accessor.  The munch combinator didn't have to change at all 
(although its inferred type did in fact change).

\subsection{Error messages}
Now we modify the remaining parsers to report accurate and useful errors.
Here's the error messages that we'll use to report each error:
\begin{verbatim}
eAppOper    =  "application: missing operator"
eAppClose   =  "application: missing close parenthesis"
eDefSym     =  "define: missing symbol"
eDefForm    =  "define: missing form"
eDefClose   =  "define: missing close curly"
eLamParam   =  "lambda: missing parameter list"
eLamDupe    =  "lambda: duplicate parameter names"
eLamPClose  =  "lambda: missing parameter list close curly"
eLamBody    =  "lambda: missing body form"
eLamClose   =  "lambda: missing close curly"
eSpecial    =  "special form: unable to parse"
eWoof       =  "woof: unparsed input"
\end{verbatim}

The MonadError type class provides two useful combinators, throwError for 
generating errors, and catchError for dealing with them.  We can ignore 
catchError because we don't need to recover from errors, just report them. 
When should an error be generated and what 
data should it include?  \verb+throwError+ is too basic for our needs, so we'll 
introduce the \verb+commit+ combinator:
\begin{verbatim}
commit :: (MonadError e m, Plus m) => e -> m a -> m a
commit err p = p <+> throwError err
\end{verbatim}
This combinator takes two arguments: 1. an error value, and 2. a monadic 
computation.  It first tries to run the computation, and if the computation 
fails, generates an error whose contents are the first argument.  The 
definition of 'failure' is provided by the \verb+Plus+ instance of \verb+m+. So 
what data do we want to include in our errors?  A String describing the error 
and a token reporting the position should describe the error decently:
\begin{verbatim}
type Error = (String, Token)
\end{verbatim}
Now lets start with \verb+Application+ as our first modified, error-reporting parser:
\begin{verbatim}
application =
    openparen                             >>= \open ->
    commit (eAppOper, open) form          >>= \op ->
    many0 form                            >>= \args ->
    commit (eAppClose, open) closeparen   >>
    return (AApp op args)
\end{verbatim}
This parser works by running the open-parenthesis parser, capturing its value 
in \verb+open+, and continuing with the parsing; if either \verb+form+ or 
close-parenthesis fails, an appropriate error can be generated which includes 
a string and the location of the open parenthesis.  However, if the open 
parenthesis is not successfully parsed, it's a failure but not an error.  
Here are some examples to demonstrate this in action:
\begin{verbatim}
*Main> runParser application (countLineCol "oops")
Right Nothing

*Main> runParser application (countLineCol "(a b c)")
Right (Just (AApp (ASymbol "a") [ASymbol "b",ASymbol "c"],[]))

*Main> runParser application (countLineCol "\n()")
Left ("application: missing operator",('(',2,1))

*Main> runParser application (countLineCol "(a b")
Left ("application: missing close parenthesis",('(',1,1))
\end{verbatim}
Although the previous version of the \verb+application+ parser was implemented 
with just applicative combinators, this version can't be:  \verb+open+ 
is used to build the following parsers, making this decidedly monadic.

The \verb+define+ and \verb+lambda+ parsers are upgraded similarly:
\begin{verbatim}
define =
    opencurly                            >>= \open ->
    check (== "define") symbol            *>
    pure ADefine                         <*>
    commit (eDefSym, open) symbol        <*>
    commit (eDefForm, open) form         <*
    commit (eDefClose, open) closecurly  

lambda =
    opencurly                                >>= \open ->
    check (== "lambda") symbol               >>
    commit (eLamParam, open) opencurly       >>= \p_open ->
    many0 symbol                             >>= \params ->
    (if distinct params 
        then return ()
        else throwError (eLamDupe, p_open))  >>
    commit (eLamPClose, p_open) closecurly   >>
    commit (eLamBody, open) (many1 form)     >>= \bodies ->
    commit (eLamClose, open) closecurly      >>
    return (ALambda params bodies)
  where
    distinct names = length names == length (nub names)
\end{verbatim}
Note that \verb+commit+ isn't used until we can be sure that we're in the right 
rule:  if, in the \verb+define+ parser, we committed to parsing the "define" 
keyword, we wouldn't be able to backtrack and try the \verb+lambda+ parser if 
that failed.  Thus, if treating errors as unrecoverable, it's important not to 
place a \verb+commit+ where backtracking might be necessary to parse a valid 
alternative.  However, this isn't the case with how we've used it, since once 
we see an open curly brace and a define, we're sure that we're in the \verb+define+
rule, and allowing backtracking would only destroy our ability to produce clean 
and accurate error reports.

\subsection{Error messages:  finishing touches}
To complete the error-reporting parser, we need to change a couple more details. 
First, we want an error reported when an open curly brace is found, but no 
special form can be reported.  To accomplish this, we can extend the \verb+special+ 
parser with a third alternative, which results in an error if it can parse
an open curly brace, but in a backtracking failure if not:
\begin{verbatim}
special = define <+> lambda <+> (ocurly >>= \o -> throwError (esName, o))
\end{verbatim}
The \verb+form+ parser doesn't have to be changed:
\begin{verbatim}
form = fmap ASymbol symbol <+> application <+> special
\end{verbatim}
When we can no longer parse any forms, instead of failing, we'd like to report an error if there's any input
left, and otherwise succeed.  To implement this parser, we'll first munch any leading whitespace or comments, 
as usual, and then we'll check the input:  if it's empty, great; if not, report an error at the location of the
first remaining token, along with the appropriate error message that we defined earlier:
\begin{verbatim}
endCheck = 
    many0 (whitespace <+> comment) *>
    get >>= \xs -> case xs of
                        (t:_) -> throwError (ewUnp, t)
                        []    -> pure ()
\end{verbatim}
Now our \verb+woof+ parser uses this \verb+endCheck+ parser after it has consumed all the forms that it can:
\begin{verbatim}
woof = many0 form <* endCheck
\end{verbatim}

\subsection{Error messages:  examples}
While correct input will be parsed in the same way by our new parsers, incorrect input will now (hopefully) be
accurately reported as such.  Successful results will be slightly different, however -- there is now an extra
constructor wrapper around the value:
\begin{verbatim}
*Main> runParser woof (countLineCol "{define fgh {lambda {f x} (f x)}}")
Right (Just ([ADefine "fgh" (ALambda ["f","x"] 
                                     [AApp (ASymbol "f") [ASymbol "x"]])],
       []))
\end{verbatim}
Here's the proof showing that the parser correctly report all of the errors 
covered by our spec:
\begin{verbatim}
*Main> let p = runParser woof . countLineCol

*Main> p "()"
Left ("application: missing operator",('(',1,1))

*Main> p "(a b"
Left ("application: missing close parenthesis",('(',1,1))

*Main> p "{define (a b c)}"
Left ("define: missing symbol",('{',1,1))

*Main> p "{define a}"
Left ("define: missing form",('{',1,1))

*Main> p "{define a b"
Left ("define: missing close curly",('{',1,1))

*Main> p "{lambda (a b c)}"
Left ("lambda: missing parameter list",('{',1,1))

*Main> p "{lambda {a b a} (a b c)}"
Left ("lambda: duplicate parameter names",('{',1,9))

*Main> p "{lambda {a b (c d)}"
Left ("lambda: missing parameter list close curly",('{',1,9))

*Main> p "{lambda {a b}}"
Left ("lambda: missing body form",('{',1,1))

*Main> p "{lambda {a b} (c d)"
Left ("lambda: missing close curly",('{',1,1))

*Main> p "{defin x y}"
Left ("special form: unable to parse",('{',1,1))

*Main> p "a,b"
Left ("woof: unparsed input",(',',1,2))
\end{verbatim}




\section{Stack Order}
Not only are the contents of a transformer stack important, but the order of the
layers as well.  Let's revisit our first woof parser -- what if our stack had
instead been Maybe/State instead of State/Maybe?
\begin{verbatim}
State/Maybe:   s -> Maybe (a, s)

Maybe/State:   s -> (Maybe a, s)
\end{verbatim}

given:
\begin{verbatim}
import Control.Monad.Trans.Maybe (MaybeT(..))
import Data.Functor.Identity     (Identity(..))

type Parser' t a = MaybeT (StateT [t] Identity) a

runParser' :: Parser' t a -> [t] -> (Maybe a, [t])
runParser' p xs = runIdentity $ runStateT (runMaybeT p) xs
\end{verbatim}
We can compare it to the earlier parser:
\begin{verbatim}
*Main> runParser' (literal 'a') "aqrs"
(Just 'a',"qrs")

*Main> runParser' (literal 'a') "qrs"
(Nothing,"rs")
\end{verbatim}
Whereas:
\begin{verbatim}
*Main> runParser (literal 'a') "qrs"
Nothing

*Main> runParser (literal 'a') "aqrs"
Just ('a',"qrs")
\end{verbatim}
The difference is that Maybe/State always returns a modified state, regardless
of the success of the computation, whereas State/Maybe only returns a modified
state if the computation is successful.  This means that backtracking doesn't
work right with Maybe/State -- tokens are consumed even when the parsers
don't match, as the example shows.

On the other hand, the order of Error and Maybe relative to each other isn't 
important.  Try it for yourself!

Another important point to note is that our parsers didn't actually specify
which order -- Maybe/State or State/Maybe -- they prefer, and in fact they will 
work with either order.  Since our parsers don't specify the stack order, the 
semantics are ultimately determined by the actual stack we use.




\section{Conclusion}
Monad transformers provide an elegant solution to error reporting in parser
combinators.  Better yet, they are extensible -- we could go back and add more
features to our parsers using additional transformers, perhaps extending our
parser to save partial results, so that if there's an error, it reports the
progress that it had made before the error.  We could do that using a Writer
transformer.  Or we check to make sure that all variables are in scope when
they're used -- using a Reader transformer.  We could even capture whitespace
and comment tokens, instead of just throwing them away, in case they contained
valuable information.  And the best part of it is, most of the parsers we already
wrote would continue to work fine without needing any modifications.  We'd just
have to set up our transformer stack and modify the relevant parsers! 




\bibliography{Author}

\end{document}

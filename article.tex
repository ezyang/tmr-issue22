% -*- LaTeX -*-
\documentclass{tmr}

\usepackage{mflogo}

%include polycode.fmt


\newcommand{\Matt}[1]{\Red{Matt: #1}}

\title{Error Reporting Parsers:  a Monad Transformer Approach}
\author{Matt Fenwick\email{mfenwick100@gmail.com}}
\author{Jay Vyas\email{jayunit100@gmail.com}}

\begin{document}


\begin{introduction}

Monad transformers are used to deal with combinations of computational
effects, including backtracking, errors, and state, in a modular and
composable way \cite{liang}.

Real-world parsers require such computational effects in order to provide
key features such as error reporting and context-sensitive results.
This article will explore how monad transformers contribute to the design
and implementation of parsers.

\end{introduction}



\section{Parser Combinators}

The goals of parsing are to: 1) decide whether a string is part of the language
in question, and 2) build a meaningful representation of the structure of the
parsed string.  In addition, practical parsers must recognize faulty input and
accurately report the location and cause of the problem.  Thus, a parser must
also decide what generates an error, what information is in the error, and how
error-reporting parsers compose.

Parser combinators are an excellent approach for building expressive, 
composable and declarative parsers.  They also benefit from host-language
integration, allowing them to snarf features such as type systems and test 
frameworks.  There are many excellent papers on parser combinators, such
as Wadler's classic paper \cite{wadler} on non-deterministic parser combinators, 
Hutton's paper which covers factoring parsers into smaller pieces \cite{hutton}, 
and Leijen's Parsec paper \cite{leijen}.  The inspiration and many of the names 
used in this article are drawn from those references.

To get a feel for what parser combinators are and how they're used to
build parsers, we'll quickly create a minimal parser combinator library to see
the basic principles of their design before adding monad transformers to
the mix.  We'll divide the library into three main pieces of the code:

\begin{itemize}
 \item Parser datatype
 \item a primitive parser
 \item type class instances
 \item combinators
\end{itemize}

\subsection{Parser datatype}

Parsers operate on token sequences, consuming tokens from the front of the sequence.
We could model this with the function type:
\begin{verbatim}
newtype Parser t = 
    Parser {getParser :: [t] -> [t]}
\end{verbatim}

We also want parsers to return a value, if they succeed.  So let's extend the return type
again to allow for a value, which also requires a second type parameter:
\begin{verbatim}
newtype Parser t a = 
    Parser {getParser :: [t] -> ([t], a)}
\end{verbatim}

However, this ignores the possibility of failure.  To allow for failure, the return value needs to
be wrapped in a Maybe:
\begin{verbatim}
newtype Parser t = 
    Parser {getParser :: [t] -> Maybe ([t], a)}
\end{verbatim}

This gives us a simple, minimal definition of a parser.  We've used
\verb+newtype+ instead of \verb+type+ so that we can create type class
instances for our parsers later on.


\subsection{A primitive parser}
The simplest parser is \verb+item+; it 
consumes a single token if available and fails otherwise:
\begin{verbatim}
item :: Parser t t
item = Parser f
  where 
    f [] = Nothing
    f (x:xs) = Just (xs, x)
\end{verbatim}

This captures the basic concept that parsers are inherently sequential --
they consume tokens left-to-right from a list.


\subsection{Type class instances}
For running multiple parsers in sequence, the combinators from the Monad and
Applicative type classes are very useful; our next step is to implement them.

First is the Functor instance, which we need since it's a superclass
of Applicative.  It just maps a function over the result value, and
relies on the Functor instances of Maybe and pairs:
\begin{verbatim}
instance Functor (Parser t) where
  fmap f (Parser p) = Parser (fmap (fmap f) . p)
\end{verbatim}

The \verb+<*>+ operator of Applicative runs parsers sequentially, 
and applies the result of the first to the result of the second; it
has to make sure that the (possibly modified) output token stream from
the first parser is passed to the second:
\begin{verbatim}  
import Control.Applicative  (Applicative(..))

instance Applicative (Parser t) where
  pure x = Parser (\xs -> pure (xs, x))
  Parser p1 <*> Parser p2 = Parser p3
    where p3 xs = case (p1 xs) of
                       Nothing      -> Nothing;
                       Just (ys, f) -> fmap (fmap f) (p2 ys)
\end{verbatim}

The Monad instance is similar to the Applicative instance, except that 
the actual result value of the first parser is used to generate the 
second parser; similarly to the Functor instance, this depends on 
instances of its underlying types:
\begin{verbatim}
instance Monad (Parser t) where
  return x = Parser (\ts -> return (ts, x))
  Parser p >>= f = Parser (\ts ->
                             p ts >>= \(ts', x) ->
                             getParser (f x) ts')
\end{verbatim}

The Alternative type class expresses choice; the instance is
is defined in terms of the Alternative instance of the
underlying result type, \verb+Maybe+.
\begin{verbatim}
import Control.Applicative  (Alternative(..))

instance Alternative (Parser t) where
  empty = Parser (const empty)
  Parser l <|> Parser r = Parser (\ts -> l ts <|> r ts)
\end{verbatim}


\subsection{Combinators}
We can capture common patterns of parser construction in combinators in 
order to make it more convenient.  The \verb+check+ combinator, analogous 
to \verb+Control.Monad.mfilter+, is used to validate a parse result:
\begin{verbatim}
check :: (Monad f, Alternative f) => (a -> Bool) -> f a -> f a
check p m =
    m >>= \x -> if p x then return x else empty
\end{verbatim}

Using \verb+check+, we can build a convenient combinator to parse specific
matching tokens: 
\begin{verbatim}
literal :: Eq t => t -> Parser t t
literal x = check (== x) item
\end{verbatim}


\subsection{Examples}
First, let's see \verb+item+ in action.  It fails on empty lists,
and succeeds consuming one token otherwise:
\begin{verbatim}
*Main> getParser item ""
Nothing

*Main> getParser item "abcde"
Just ("bcde",'a')
\end{verbatim}

We can run parsers in sequence using the Applicative combinators.  First one parser
is run, then the second, and the token position is threaded between the two.
Note that both parsers must succeed in order for the combined parser to succeed:
\begin{verbatim}
*Main> getParser (item *> item) "abcde"
Just ("cde",'b')

*Main> getParser (fmap (,) item <*> item) "abcde"
Just ("cde",('a','b'))

*Main> getParser (item *> item) "a"
Nothing
\end{verbatim}

Parsers built out of \verb+literal+ only succeed when the next token matches 
the specified one:
\begin{verbatim}
*Main> getParser (literal 'a') "abcde"
Just ("bcde",'a')

*Main> getParser (literal 'a') "bcde"
Nothing
\end{verbatim}

Using the Alternative combinators, we can create parsers that succeed if any of
their sub-parsers succeed.  This is what allows parsers to backtrack, trying
various alternatives if one fails:
\begin{verbatim}
*Main> getParser (literal 'a' <|> literal 'b') "abcde"
Just ("bcde",'a')

*Main> getParser (literal 'a' <|> literal 'b') "bacde"
Just ("acde",'b')

*Main> getParser (literal 'a' <|> literal 'b') "cdeab"
Nothing
\end{verbatim}
Finally, let's parse arbitrarily deeply nested parentheses.  This example 
demonstrates the use of \verb+fmap+ to apply a function to a parse result, 
\verb+check+ to make sure that \verb+char+ doesn't consume parentheses,
\verb+literal+ to match specific tokens exactly, \verb+many+ to introduce
repetition, \verb+<|>+ to express choice, and \verb+*>+ 
and \verb+<*+ to sequence parsers:
\begin{verbatim}
data Nesting
    = One Char
    | Many [Nesting]
  deriving (Show, Eq)
  
char :: Parser Char Nesting
char = fmap One $ check (not . flip elem "()") item

level :: Parser Char Nesting
level = literal '(' *> (fmap Many $ many element) <* literal ')'

element :: Parser Char Nesting
element = char <|> level

parseNest :: Parser Char [Nesting]
parseNest = many element
\end{verbatim}
Examples:
\begin{verbatim}
*Main> getParser parseNest "(((()))))"
Just (")",[Many [Many [Many [Many []]]]])

*Main> getParser parseNest "(()abc(def)())zy"
Just ("",[Many [Many [],One 'a',One 'b',One 'c',
                Many [One 'd',One 'e',One 'f'],Many []],
          One 'z',
          One 'y'])

*Main> getParser parseNest "(()abc(def)()"
Just ("(()abc(def)()",[])
\end{verbatim}
That concludes the implementation of a simple parser.
In the rest of this article, we'll rework and augment these basic parser 
combinators by generalizing the implementations and extending the result types,
while taking advantage of monad transformers to keep them modular.




\section{Monad transformers}

How can we use monad transformers to help us create parsers and parser combinators?
The parser type we used earlier -- \verb+[t] -> Maybe ([t], a)+
-- can be built out of the StateT monad transformer (from the standard 
mtl \cite{mtl} library) applied to Maybe.  Here's the StateT implementation:
\begin{verbatim}
newtype StateT s m a = StateT { runStateT :: s -> m (a,s) }
\end{verbatim}

Substituting in [s] for s and Maybe for m in the right-hand side produces
(note that the type variable m is no longer needed):
\begin{verbatim}
newtype StateT s a = StateT { runStateT :: [s] -> Maybe (a,[s]) }
\end{verbatim}

This is identical to the Parser type given before, except for the order 
of the result tuple, and so we can redefine the parser type as:
\begin{verbatim}
import Control.Monad.State       (StateT(..))

type Parser t a = StateT [t] Maybe a
\end{verbatim}

The \verb+item+ parser is reimplemented using the combinators from MonadState --
token lists are the `state' that \verb+item+ must inspect and modify:
\begin{verbatim}
{-# LANGUAGE   FlexibleContexts  #-}

import Control.Monad.State       (MonadState (..))

item :: (MonadState [t] m, Alternative m) => m t
item =
    get >>= \xs -> case xs of
                        (t:ts) -> put ts *> pure t;
                        []     -> empty;
\end{verbatim}

There are two major benefits to our parsers from using monad transformers:
\begin{itemize}
 \item semantic building blocks -- the mtl library provides implementations
    for Maybe, Error, and State building blocks; using these, we can describe
    describe the semantics of our parsers, and
 \item type class instances -- in addition to providing the building blocks,
    the mtl provides instances for common type classes, so we only have to 
    worry about parser-specific operations.
\end{itemize}




\section{Introducing Woof:  a Simple Lisp}

The simple language we'll use as a motivation for building parsers is Woof, a 
simple dialect of Lisp.  We'll be progressively adding features to a simple 
initial implementation on our way to creating an error-reporting parser.

The language definition in pseudo-BNF \cite{bnf} is:

\begin{verbatim}
Woof         :=   Form(+)
Form         :=   Symbol  |  Special  |  Application
Symbol       :=   [a-zA-Z](+)
Special      :=   '{'  ( Define  |  Lambda )  '}'
Define       :=   'define'  Symbol  Form
Lambda       :=   'lambda'  '{'  Symbol(*)  '}'  Form(+)
Application  :=   '('  Form(+)  ')'
Whitespace   :=   \s+
Comment      :=   ';'  (not '\n')(*)
\end{verbatim}

With the additional rule that whitespace and comments may appear in any 
amount before or after tokens.  Tokens are:
\begin{itemize}
  \item \verb+{+
  \item \verb+}+
  \item \verb+(+
  \item \verb+)+
  \item \verb+Symbol+
\end{itemize}




\section{Example 1: Recognition and Tree-Building}

\subsection{Preliminaries}
Our first Woof parser will be responsible for determining whether input
text conforms to the language definition and building an 
Abstract Syntax Tree (AST) representing the structure of the parsed input.
Here's the AST definition we'll use:
\begin{verbatim}
data AST
    = ASymbol String
    | ALambda [String] [AST]
    | ADefine String AST
    | AApp    AST  [AST]
  deriving (Show, Eq)
\end{verbatim}

We'll also want a function for running our parsers, using the type given in the
prevous section:
\begin{verbatim}
runParser :: Parser [t] a -> [t] -> Maybe (a, [t])
runParser = runStateT
\end{verbatim}

\subsection{Token parsers}
Our first parsers are for the most basic syntactic elements:  tokens.
These include the four braces, symbols, strings, numbers, whitespace, and comments.
To recognize braces, we use the \verb+item+ and \verb+check+ 
combinators to build a new combinator, \verb+satisfy+, that checks whether 
the next character meets a condition:
\begin{verbatim}
satisfy :: (MonadState [t] m, Alternative m) => (t -> Bool) -> m t
satisfy = flip check item
\end{verbatim}

Because we used MonadState's combinators to build \verb+item+, \verb+literal+ 
has a slightly different type; we also take advantage of \verb+satisfy+ to 
simplify its implementation:
\begin{verbatim}
literal :: (Eq t, MonadState [t] m, Alternative m) => t -> m t
literal c = satisfy ((==) c)
\end{verbatim}

Now we're ready to build parsers for the four bracket tokens.  
First, a simple bracket parser:
\begin{verbatim}
opencurly = literal '{'
\end{verbatim}

It accepts open curly brackets and rejects everything else:
\begin{verbatim}
*Main> map (runParser  opencurly) ["{abc", "}abc", "(abc", "abc"]
[Just ('{', "abc"), Nothing, Nothing, Nothing]
\end{verbatim}

But what about the spec that said that comments and whitespace can occur 
anywhere before or after tokens -- how should that be handled?

First we need to define the whitespace and comment patterns -- and also rename
the \verb+some+ and \verb+many+ functions from Control.Alternative to more
clearly indicate their semantics:
\begin{verbatim}
many0 = many
many1 = some

whitespace = many1 $ satisfy (flip elem " \n\t\r\f")
comment = pure (:) <*> literal ';' <*> many0 (not1 $ literal '\n')
\end{verbatim}

We want to throw away comments and whitespace, and let's throw them away after 
every token.  Let's do that using a combinator which first parses a token, and 
then throws away junk:
\begin{verbatim}
junk = many0 (whitespace <|> comment) 

tok p = p <* junk
\end{verbatim}

The comment parser uses a new combinator, \verb+not1+, built out of a 
type class, Switch, modeling computations which can be switched from
successful to failing and vice versa:
\begin{verbatim}
class Switch f where
  switch :: f a -> f ()

instance Switch Maybe where
  switch (Just _) = Nothing
  switch Nothing  = Just ()

instance (Functor m, Switch m) => Switch (StateT s m) where
  switch (StateT f) = StateT g
    where 
      g s = fmap (const ((), s)) . switch $ f s

not1 :: (MonadState [t] m, Alternative m, Switch m) => m a -> m t
not1 p = switch p *> item
\end{verbatim}

With \verb+tok+ in hand, we fix \verb+opencurly+ and try it out:
\begin{verbatim}
opencurly = tok $ literal '{'

*Main> runParser opencurly "{;abc\ndef"
Just ('{', "def")

*Main> runParser opencurly "(def"
Nothing
\end{verbatim}

Excellent!  The \verb+opencurly+ parser matches an open curly brace, failing
otherwise, and discard trailing whitespace and comments.

It's straightforward to define parsers for the other three brace tokens:
\begin{verbatim}
closecurly = tok $ literal '}'
openparen  = tok $ literal '('
closeparen = tok $ literal ')'
\end{verbatim}

The parser for our last token, Symbol, is more complicated because any number of
alphabetical characters is valid.  We'll use \verb+satisfy+ and a
predicate to check that a character is valid, and \verb+many1+ to 
match one or more valid characters:
\begin{verbatim}
symbol = tok $ many1 char
  where char = satisfy (flip elem (['a' .. 'z'] ++ ['A' .. 'Z']))

*Main> runParser symbol "abc123"
Just ("abc","123")

*Main> runParser symbol "abc;sdfasdfsa\n  123"
Just ("abc","123")

*Main> runParser symbol "123;sdfasdfsa\n  abc"
Nothing
\end{verbatim}

Note that we again use \verb+tok+ to throw away trailing junk.


\subsection{Syntactic structures}
Whereas our token parsers dealt with the syntactic primitives of the Woof grammar, 
the remaining parsers will implement grammar rules that combine the tokens
into syntactic structures.

The first combining form is function application.  The rule says that it's delimited
by matching parentheses, in between which must appear one form as the operator, followed
by any number of forms as the arguments to which the operator is applied.  We can
say that like so:
\begin{verbatim}
application =
    openparen    *>
    pure AApp   <*>
    form        <*>
    many0 form  <*
    closeparen
\end{verbatim}

Note that all the parser sequencing is done using Applicative
combinators -- we don't need to use the monadic ones.  Also, we used \verb+pure+ 
to inject a value -- the function \verb+AApp+ -- into the parser.  \verb+pure+ 
has no effect on the tokens and always succeeds:
\begin{verbatim}
*Main> runParser (pure 3) ""
Just (3,"")

*Main> runParser (pure 3) "abc"
Just (3,"abc")
\end{verbatim}

Next, we move on to the special forms.  All special forms are delimited with
curly braces, and lambda and define are our special forms, so we have:

\begin{verbatim}
special = opencurly *> (define <|> lambda) <* closecurly
\end{verbatim}

A straightforward translation of define from the grammar produces:
\begin{verbatim}
define =
    check (== "define") symbol   *>
    pure ADefine                <*>
    symbol                      <*>
    form
\end{verbatim}

On to Lambda!  Not only does Lambda have additional syntax with its parameter 
list, but we also need to ensure that the parameter names are unique.  We can 
do that using the \verb+check+ combinator again:
\begin{verbatim}
lambda = 
    check (== "lambda") symbol      *>
    opencurly                       *>
    pure ALambda                   <*>
    check distinct (many0 symbol)  <*>
    (closecurly                     *>
     many1 form)
  where
    distinct names = length names == length (nub names)
\end{verbatim}

If the symbols are distinct, the parameter list subparser will succeed,
whereas if there's a repeated symbol, it will fail.


\subsection{Finishing touches}
All we have left to do are \verb+form+ (which we've already used recursively
to build the previous parsers) and \verb+woof+.  

A form is either a symbol, application, or a special form.  We could just write:
\begin{verbatim}
form = symbol <+> application <+> special
\end{verbatim}

except that the types don't match -- \verb+symbol+'s type parameter is a String, 
whereas the other two have ASTs.  We fix that by mapping the \verb+ASymbol+ 
function over \verb+symbol+:
\begin{verbatim}
form = fmap ASymbol symbol <+> application <+> special
\end{verbatim}

The final parser, \verb+woof+, needs to not only parse all the forms, but also 
make sure that the entire input is consumed.  The end of input check is done 
with the \verb+end+ parser:
\begin{verbatim}
endCheck = switch item
\end{verbatim}

We also need to discard leading comments and whitespace, so the final Woof 
parser is:
\begin{verbatim}
woof = junk *> many0 form <* endCheck
\end{verbatim}


\subsection{Examples}
Let's look at a few examples of our parser in action.  Here are a couple of
successful examples:
\begin{verbatim}
*Main> runParser woof "; \n   {lambda {x y z} a b (c b a)}end"
Just ([ALambda ["x","y","z"] 
               [ASymbol "a",
                ASymbol "b",
                AApp (ASymbol "c") 
                     [ASymbol "b",
                      ASymbol "a"]],
       ASymbol "end"],
      "")

*Main> runParser woof "a b c {define q (f x)}"
Just ([ASymbol "a",
       ASymbol "b",
       ASymbol "c",
       ADefine "q" (AApp (ASymbol "f") [ASymbol "x"])],"")
\end{verbatim}

And a failing one:
\begin{verbatim}
*Main> runParser woof "a b c {define q (f x)},"
Nothing
\end{verbatim}

Note that while the first two parses consume the entire input, while the last 
one fails because it doesn't recognize the trailing comma.




\section{Example 2: error-reporting}
While our first parser worked great on valid input, it wasn't helpful
when the input was malformed.  When the parser finds bad input, we'd like it to 
produce an informative error, indicating what and where the problem was.  
This allows a user to quickly find and correct problems.

Let's start with an informal spec of different cases of malformed input, along 
with the error messages that should be reported: 
\begin{itemize}
  \item application: missing operator:  \begin{verbatim}()\end{verbatim}
  \item application: missing close parenthesis:  \begin{verbatim}(a b\end{verbatim}
  \item define: missing symbol:  \begin{verbatim}{define (a b c)}\end{verbatim}
  \item define: missing form:  \begin{verbatim}{define a}\end{verbatim}
  \item lambda: missing parameter list:  \begin{verbatim}{lambda (a b c)}\end{verbatim}
  \item lambda: duplicate parameter names:  \begin{verbatim}{lambda {a b a} (c d)}\end{verbatim}
  \item lambda: missing parameter list close curly:  \begin{verbatim}{lambda {a b (c d)}\end{verbatim}
  \item lambda: missing body form:  \begin{verbatim}{lambda {a b}}\end{verbatim}
  \item special form: unable to parse:  \begin{verbatim}{defin x y}\end{verbatim}
  \item special form: missing close curly:  \begin{verbatim}{define x y\end{verbatim}
  \item woof: unparsed input:  \begin{verbatim}a,b\end{verbatim}
\end{itemize}

To allow error reporting in our parsers, we first need to extend our monad stack, 
adding in a layer for errors.  We'll use a second monad transformer type class 
-- MonadError, replace the Maybe layer with its corresponding transformer datatype 
MaybeT, and add in an Either layer on the bottom of the stack.  Our parser stack 
and \verb+runParser+ function are now:
\begin{verbatim}
type Parse e t a = StateT [t] (MaybeT (Either e)) a

runParser :: Parse e t a -> [t] -> Either e (Maybe (a, [t]))
runParser p xs = runMaybeT (runStateT p xs)
\end{verbatim}

While our previous parsers had two different results -- Nothing and Just --
our new parsers have three possible results:  success, failure, and error. 
A parse failure means that a parser wasn't able to match the input, but
nothing bad happened; failures can be recovered from if there is an alternative
parse that succeeds.  However, an error means that an unrecoverable problem
has been found and that parsing should immediately stop; the parser will
not be able to recover, even if there are alternatives since backtracking
will not be performed.
Note that successful and failing parses are wrapped in an additional \verb+Right+
constructor:
\begin{verbatim}
*Main> runParser item "abc"
Right (Just ('a',"bc"))

*Main> runParser item ""
Right Nothing

*Main> runParser (throwError "oops!") ""
Left "oops!"
\end{verbatim}

Although the \verb+<|>+ combinator can recover from failures, it can't recover from
errors.  Compare:
\begin{verbatim}
*Main> runParser (satisfy (== 'a') <|> satisfy (== 'b')) "babc"
Right (Just ('b',"abc"))

*Main> runParser (throwError "no!" <|> satisfy (== 'b')) "babc"
Left "no!"
\end{verbatim}

We'll take advantage of this backtracking restriction to produce accurate error
messages.


\subsection{Type Class Preliminaries}
Unfortunately, the standard MonadError instance for the \verb+Either+ datatype does
not fit our needs -- it requires an \verb+Error+ constraint that we do not want.
We'll implement our own MonadError type class, based on the
standard one, and instances of it.  We'll need an instance for each member of
our stack -- Either, StateT, and MaybeT: 
\begin{verbatim}
class Monad m => MonadError e m | m -> e where
  throwError :: e -> m a
  catchError :: m a -> (e -> m a) -> m a

instance MonadError e (Either e) where
  throwError               =  Left
  catchError  (Right x) _  =  Right x
  catchError  (Left e)  f  =  f e
  
instance MonadError e m => MonadError e (StateT s m) where
  throwError      =  lift . throwError
  catchError m f  =  StateT g
    where
      g s = catchError (runStateT m s) 
                       (\e -> runStateT (f e) s)

instance MonadError e m => MonadError e (MaybeT m) where
  throwError      =  lift . throwError
  catchError m f  =  MaybeT $ catchError (runMaybeT m) 
                                         (runMaybeT . f)
\end{verbatim}
Note how the StateT and MaybeT instances don't really do anything with the
errors; they just pass the error on through to the next level.  That's why they
both require that the next lower level supports MonadError.  Also, this code 
requires some additional extensions:
\begin{itemize}
  \item FlexibleInstances
  \item FunctionalDependencies
  \item UndecidableInstances 
\end{itemize}

We'll also need an instance of Switch for MaybeT:
\begin{verbatim}
instance Functor m => Switch (MaybeT m) where
  switch (MaybeT m) = MaybeT (fmap switch m)
\end{verbatim}

\subsection{Error messages}
We must modify the remaining parsers to report meaningful error messages; let's
define the messages that will be reported in each case:
\begin{verbatim}
eAppOper    =  "application: missing operator"
eAppClose   =  "application: missing close parenthesis"
eDefSym     =  "define: missing symbol"
eDefForm    =  "define: missing form"
eLamParam   =  "lambda: missing parameter list"
eLamDupe    =  "lambda: duplicate parameter names"
eLamPClose  =  "lambda: missing parameter list close curly"
eLamBody    =  "lambda: missing body form"
eSpecClose  =  "special form: missing close curly"
eSpecial    =  "special form: unable to parse"
eWoof       =  "woof: unparsed input"
\end{verbatim}

The MonadError type class provides two useful combinators: \verb+throwError+ for 
generating errors and \verb+catchError+ for dealing with them.  We can ignore 
the second because we don't need to recover from errors, just report them, 
but when should an error be generated and what 
data should it include?  \verb+throwError+ is too basic for our needs, so we'll 
introduce the \verb+commit+ combinator:
\begin{verbatim}
commit :: (MonadError e m, Alternative m) => e -> m a -> m a
commit err p = p <|> throwError err
\end{verbatim}

This combinator takes two arguments: an error value and a monadic 
computation.  It first tries to run the computation; if the computation 
fails, it generates an error.  The 
definition of 'failure' is provided by the Alternative instance of \verb+m+.
The reason for its name is that it restricts backtracking and alternatives;
it ``commits" the parser to a do-or-die situation -- either it successfully
parses the input, or the parsing stops.  It's based on the \verb+nofail+
combinator of \cite{hutton1992higher}.

What data do we want to include in our errors?  A String describing the error 
and a token reporting the position will do:
\begin{verbatim}
type Error = String
\end{verbatim}

We'll first add error-reporting to \verb+application+:
\begin{verbatim}
application =
    openparen                     >>
    commit eAppOper form          >>= \op ->
    many0 form                    >>= \args ->
    commit eAppClose closeparen   >>
    return (AApp op args)
\end{verbatim}

This parser works by first running the open-parenthesis parser; then, if either 
\verb+form+ or close-parenthesis fails, an appropriate error is generated with 
a message describing the problem.  However, if the open 
parenthesis is not successfully parsed, it's a failure but not an error.  
Examples:
\begin{verbatim}
*Main> runParser application "oops"
Right Nothing

*Main> runParser application "(a b c)"
Right (Just (AApp (ASymbol "a") [ASymbol "b",ASymbol "c"],""))

*Main> runParser application "\n()"
Left "application: missing operator"

*Main> runParser application "(a b"
Left "application: missing close parenthesis"
\end{verbatim}

The \verb+define+ and \verb+lambda+ parsers are upgraded similarly:
\begin{verbatim}
define =
    check (== "define") symbol    *>
    pure ADefine                 <*>
    commit eDefSym symbol        <*>
    commit eDefForm form
    
lambda =
    check (== "lambda") symbol       >>
    commit eLamParam opencurly       >>
    many0 symbol                     >>= \params ->
    (if distinct params 
        then return ()
        else throwError eLamDupe)    >>
    commit eLamPClose closecurly     >>
    commit eLamBody (many1 form)     >>= \bodies ->
    return (ALambda params bodies)
  where
    distinct names = length names == length (nub names)
\end{verbatim}

Note that \verb+commit+ isn't used until we can be sure that we're in the right 
rule: if, in the \verb+define+ parser, we committed to parsing the ``define" 
keyword, we wouldn't be able to backtrack and try the \verb+lambda+ parser if 
that failed.  Thus, if errors are treated as unrecoverable, it's important not to 
place a \verb+commit+ where backtracking might be necessary to parse a valid 
alternative.  In our example, however, once 
we see an open curly brace and a define, we're sure that we're in the \verb+define+
rule; allowing useless backtracking would only destroy our ability to report 
errors cleanly and accurately.

\subsection{Error messages:  finishing touches}
To complete the error-reporting parser, we need to change a couple more details. 
First, we want an error reported when an open curly brace is found, but no 
special form can be parsed.  We extend the \verb+special+ 
parser to report an error if it matches an open brace but not define or lambda:
\begin{verbatim}
special = 
    opencurly  *>  commit eSpecial (define <|> lambda)  <*  commit eSpecClose closecurly
\end{verbatim}

The \verb+form+ parser doesn't have to be changed:
\begin{verbatim}
form = fmap ASymbol symbol <+> application <+> special
\end{verbatim}

When we can no longer parse any forms, instead of failing, we'd like to report 
an error if there's any input left, and otherwise succeed:
\begin{verbatim}
woof = junk *> many0 form <* commit eWoof endCheck
\end{verbatim}


\subsection{Error messages:  examples}
While correct input is still parsed successfully:
\begin{verbatim}
*Main> runParser woof "{define fgh {lambda {f x} (f x)}}"
Right (Just ([ADefine "fgh" (ALambda ["f","x"] 
                                     [AApp (ASymbol "f") 
                                           [ASymbol "x"]])],
       []))
\end{verbatim}

Incorrect input results in an error.  For each of the items in our error spec, 
we can show that our parser correctly reports an error: 
\begin{verbatim}
*Main> runParser woof "(a b"
Left "application: missing close parenthesis"

*Main> runParser woof "{define (a b c)}"
Left "define: missing symbol"
\end{verbatim}

And so on.




\section{Example 3: reporting position}

Knowing that a close-parenthesis is missing somewhere deep inside a nested mess
of forms isn't very helpful -- you also want to know where it happened.  Let's 
add that to our parser.


\subsection{Parser type}

Once again, we extend the monad transformer stack with another layer -- a second
state layer, in which the line and column position will be kept as simple Ints.
The error type is also extended to include a position as well as a message:
\begin{verbatim}
type Pos = (Int, Int)
type Err = (String, Pos)

type Parser t a = StateT [t] (StateT Pos (MaybeT (Either Err))) a 
\end{verbatim}

\verb+runParser+ is extended to support the new stack; it assumes we always
start parsing at line 1, column 1:
\begin{verbatim}
runParser :: Parser t a -> [t] -> Either Err (Maybe ((a, [t]), Pos))
runParser p ts = runMaybeT $ runStateT (runStateT p ts) (1, 1)
\end{verbatim}

Now that we have two separate state layers, we need to be sure not to mix them 
up (fortunately, Haskell's type system will helpfully complain if I mess up);
the \verb+lift+ method of the \verb+MonadTrans+ type class allows us to access
the position state:
\begin{verbatim}
getState :: Parser Char Pos
getState = lift get

putState :: Pos -> Parser Char ()
putState = lift . put

updateState :: (Pos -> Pos) -> Parser Char ()
updateState f = getState >>= (putState . f)
\end{verbatim}

We also need to update \verb+item+, such that when it consumes a character, 
it updates the line/column position.  We'll do this by splitting it into two
parts, the part that consumes a single character, and the part that updates the
position:
\begin{verbatim}
basic_item :: (MonadState [t] m, Alternative m) => m t
basic_item =
    get >>= \xs -> case xs of
                        (t:ts) -> put ts *> pure t;
                        []     -> empty;

item :: Parser Char Char
item = basic_item >>= \x -> updateState (f x) >> pure x
  where f '\n' (ln, c) = (ln + 1, 1)
        f _    (ln, c) = (ln, c + 1)
\end{verbatim}

For simplicity, only '\n' characters will count as newlines; every other character,
including tabs, will count as a single column on the same line.


\subsection{Position reporting}
To actually report the position when an error is detected, we introduce a new 
combinator, which I'll call \verb+cut+:
\begin{verbatim}
cut :: String -> Parser Char a -> Parser Char a
cut message parser = 
    getState >>= \p ->
    commit (message, p) parser
\end{verbatim}

It checks the current position, runs a parser, and if the parser fails, reports
an error consiting of a message and the position.

To take advantage of this combinator, we essentially replace every use of 
\verb+commit+ with \verb+cut+:
\begin{verbatim}
application =
    openparen                     >>
    cut eAppOper form             >>= \op ->
    many0 form                    >>= \args ->
    cut eAppClose closeparen      >>
    return (AApp op args)

define =
    check (== "define") symbol    *>
    pure ADefine                 <*>
    cut eDefSym symbol           <*>
    cut eDefForm form

lambda =
    check (== "lambda") symbol     >>
    cut eLamParam opencurly        >>
    many0 symbol                   >>= \params ->
    (if distinct params 
        then return ()
        else cut eLamDupe empty)      >>
    cut eLamPClose closecurly         >>
    cut eLamBody (many1 form)         >>= \bodies ->
    return (ALambda params bodies)
  where
    distinct names = length names == length (nub names)

special = 
    opencurly  *>  cut eSpecial (define <|> lambda)  <*  cut eSpecClose closecurly

form = fmap ASymbol symbol <|> application <|> special

woof = junk *> many0 form <* cut eWoof end
\end{verbatim}

Now the parsers report useful errors:
\begin{verbatim}
*Main> runParser woof " abc 123 "
Left ("woof: unparsed input",(1,6))

*Main> runParser woof " (((abc ())) "
Left ("application: missing operator",(1,10))

*Main> runParser woof "{define const \n  {lambda {x x} \n   x}"
Left ("lambda: duplicate parameter names",(2,15))
\end{verbatim}




\Red{It's worth noting that up until this point, 
we haven't talked about how transformers contribute to the design of the parser library.  
Maybe give the juicy bits earlier.}

\section{Stack Order}
While the contents of a transformer stack is important, the order of the
layers is important as well~\cite{stack}.  Let's revisit our first Woof parser -- what if our 
stack had been Maybe/State instead of State/Maybe?
\begin{verbatim}
State/Maybe:   s -> Maybe (a, s)

Maybe/State:   s -> (Maybe a, s)
\end{verbatim}

given:
\begin{verbatim}
import Control.Monad.Trans.Maybe (MaybeT(..))
import Data.Functor.Identity     (Identity(..))

type Parser' t a = MaybeT (StateT [t] Identity) a

runParser' :: Parser' t a -> [t] -> (Maybe a, [t])
runParser' p xs = runIdentity $ runStateT (runMaybeT p) xs
\end{verbatim}

We can compare it to the earlier parser:
\begin{verbatim}
*Main> runParser' (literal 'a') "aqrs"
(Just 'a',"qrs")

*Main> runParser' (literal 'a') "qrs"
(Nothing,"rs")
\end{verbatim}
Whereas:
\begin{verbatim}
*Main> runParser (literal 'a') "qrs"
Nothing

*Main> runParser (literal 'a') "aqrs"
Just ('a',"qrs")
\end{verbatim}

The difference is that Maybe/State always returns a modified state, regardless
of the success of the computation, whereas State/Maybe only returns a modified
state if the computation is successful.  This means that backtracking doesn't
work right with Maybe/State -- tokens are consumed even when the parsers
don't match, as the example shows.

On the other hand, the order of Error and Maybe relative to each other isn't 
important.  We can show this by losslessly converting values from one stack to 
the other and back:
\begin{verbatim}
type Stack1 e a = Either e (Maybe a)
type Stack2 e a = Maybe (Either e a)

forward :: Stack1 e a -> Stack2 e a
forward (Left e)          =  Just $ Left e
forward (Right Nothing)   =  Nothing
forward (Right (Just x))  =  Just $ Right x

backward :: Stack2 e a -> Stack1 e a
backward Nothing           =  Right Nothing
backward (Just (Left e))   =  Left e
backward (Just (Right x))  =  Right $ Just x

identityForward :: Stack1 e a -> Stack1 e a
identityForward = backward . forward

identityBackward :: Stack2 e a -> Stack2 e a
identityBackward = forward . backward
\end{verbatim}

No partial functions were used.  Now we can use these functions to
convert between the two stacks.  Note the final result is the same as the input:
\begin{verbatim}
vals = [Left "an error", Right Nothing, Right $ Just "success"]

*Main> map forward vals
[Just (Left "an error"),Nothing,Just (Right "success")]

*Main> map identityForward vals
[Left "an error",Right Nothing,Right (Just "success")]
\end{verbatim}

Another important point is that our parsers don't specify
which order -- Maybe/State or State/Maybe -- they prefer, and will 
work with either.  This means that the semantics are ultimately determined by 
the actual monad stack we use.




\section{Monad transformer motivation}
Let's take a quick look at what we've done from a different perspective that
may help motivate why monad transformers were used.

In the first parser, we could parse valid input, but invalid input left us with
absolutely no idea what the problem was or where:
\begin{verbatim}
*Main> runParser woof " {define const {lambda {x x} x}} "
Nothing
\end{verbatim}

The second parser reported what the problem was, but not where:
\begin{verbatim}
*Main> runParser woof " {define const {lambda {x x} x}} "
Left "lambda: duplicate parameter names"
\end{verbatim}

And the third parser was able to report both what and where the problem occurred:
\begin{verbatim}
*Main> runParser woof " {define const {lambda {x x} x}} "
Left ("lambda: duplicate parameter names",(1,25))
\end{verbatim}

Thus, a key to the usefulness of the last parser is that it supports monadic
effects -- backtracking, error reporting, and state.  The parsers which supported 
fewer effects were not as useful.

This emphasizes some major advantages of using monad transformers:
\begin{itemize}
 \item it's easy to create stacks supporting multiple effects
 \item type class instances are taken care of by the library, so stacks already
       support many useful combinators
 \item it's easy to change the composition and order of stacks
\end{itemize}

We benefitted from these advantages when many of the parsers didn't have to change 
at all from one version to the next (although some of their types did change).




\Section{Parsec comparison}
A quick word about Parsec \cite{leijen}, a popular and battle-tested parser 
combinator library for Haskell:

The approach I've described differs from Parsec's approach with respect to 
backtracking and error-reporting.  By default, Parsec generates LL(1) parsers --
this means it uses predictive parsing with only a single token of lookahead.  This
is useful for both efficiency and better error reporting.  However, often a 
single token is not enough to unambiguously determine what rule should be tried;
for these cases, one must use its \verb+try+ combinator.  It is up to the
programmer to determine when it's necessary to add \verb+try+ to a parser
implementation.

On the other hand, my approach by default uses unlimited lookahead; it also 
doesn't automatically generate meaningful errors.  It is up to the programmer 
to generate useful errors using the \verb+throwError+ and \verb+commit+ 
combinators.




\section{Conclusion}
Monad transformers provide an elegant solution to error reporting in parser
combinators.  Better yet, they are extensible -- we could go back and add more
features to our parsers using additional transformers, perhaps extending our
parser to save partial results, so that if there's an error, it reports the
progress that it had made before the error.  We could do that using a Writer
transformer.  Or we check to make sure that all variables are in scope when
they're used -- using a Reader transformer.  We could even capture whitespace
and comment tokens, instead of just throwing them away, in case they contained
valuable information.  And the best part of it is, most of the parsers we already
wrote would continue to work fine without needing any modifications.  That
is the power of monad transformers!




\bibliography{article}

\end{document}
